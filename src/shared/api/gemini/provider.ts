import {
  GoogleGenAI,
  FinishReason,
  GenerateContentResponse
} from '@google/genai';
import type {
  Content,
  FunctionCall,
  Part,
  PartUnion,
  Tool
} from '@google/genai';
import type { Message, Model, MCPTool, MCPToolResponse as GlobalMCPToolResponse } from '../../types';
import { ChunkType } from '../../types/chunk';
import { getMainTextContent } from '../../utils/messageUtils';

import {
  isGemmaModel,
  isWebSearchModel
} from '../../config/models';
import { takeRight } from 'lodash';
import { filterUserRoleStartMessages, filterEmptyMessages } from '../../utils/messageUtils/filters';
import { withRetry } from '../../utils/retryUtils';

import { GeminiConfigBuilder } from './configBuilder';
import { createGeminiEmbeddingService } from './embeddingService';
import { createGeminiMessageContentService } from './messageContentService';
import { fetchModels, createClient, testConnection } from './client';
import { createAbortController } from '../../utils/abortController';
import { parseAndCallTools, getMCPSystemPrompt } from '../../utils/mcpToolParser';





// æ¥å£å®šä¹‰
interface CompletionsParams {
  messages: Message[];
  assistant: any;
  mcpTools: MCPTool[];
  mcpMode?: 'prompt' | 'function';  // å·¥å…·è°ƒç”¨æ¨¡å¼
  onChunk: (chunk: any) => void;
  onFilterMessages: (messages: Message[]) => void;
}

interface MCPToolResponse {
  toolUseId?: string;
  toolCallId?: string;
  tool: MCPTool;
}

interface MCPCallToolResponse {
  isError: boolean;
  content: string;
}



// åŸºç¡€Providerç±»
export abstract class BaseProvider {
  protected model: Model;
  protected sdk: GoogleGenAI;

  constructor(model: Model) {
    this.model = model;
    this.sdk = createClient(model);
  }

  protected getAssistantSettings(assistant: any) {
    // è·å–åŸå§‹maxTokenså€¼
    const maxTokens = Math.max(assistant?.maxTokens || assistant?.settings?.maxTokens || 4096, 1);

    // ğŸ”§ ä¿®å¤ï¼šæ£€æŸ¥å¤šä¸ªå¯èƒ½çš„ä½ç½®è·å– streamOutput è®¾ç½®
    // å¯èƒ½åœ¨ assistant.settings.streamOutput æˆ– assistant.streamOutput
    const streamOutputValue = assistant?.settings?.streamOutput ?? assistant?.streamOutput;
    const streamOutput = streamOutputValue !== false;

    console.log(`[GeminiProvider] getAssistantSettings:`, {
      'assistant.settings.streamOutput': assistant?.settings?.streamOutput,
      'assistant.streamOutput': assistant?.streamOutput,
      'streamOutputValue': streamOutputValue,
      'streamOutput (final)': streamOutput
    });

    return {
      contextCount: assistant?.settings?.contextCount || 10,
      maxTokens: maxTokens,
      streamOutput: streamOutput
    };
  }



  protected createAbortController(messageId?: string, autoCleanup = false) {
    // ä½¿ç”¨ç»Ÿä¸€çš„ createAbortController å·¥å…·å‡½æ•°
    return createAbortController(messageId, autoCleanup);
  }

  protected async getMessageContent(message: Message): Promise<string> {
    return getMainTextContent(message);
  }

  public convertMcpTools<T>(mcpTools: MCPTool[]): T[] {
    return mcpTools.map((tool) => {
      let toolName = tool.id || tool.name;

      // æ¸…ç†å·¥å…·åç§°
      if (/^\d/.test(toolName)) toolName = `mcp_${toolName}`;
      toolName = toolName.replace(/[^a-zA-Z0-9_.-]/g, '_');
      if (toolName.length > 64) toolName = toolName.substring(0, 64);
      if (!/^[a-zA-Z_]/.test(toolName)) toolName = `tool_${toolName}`;

      return {
        functionDeclarations: [{
          name: toolName,
          description: tool.description,
          parameters: tool.inputSchema
        }]
      };
    }) as T[];
  }

  protected setupToolsConfig<T>({ mcpTools, enableToolUse }: {
    mcpTools: MCPTool[];
    model: Model;
    enableToolUse: boolean;
  }): { tools: T[] } {
    if (!enableToolUse || !mcpTools?.length) return { tools: [] };
    return { tools: this.convertMcpTools<T>(mcpTools) };
  }

  protected get useSystemPromptForTools(): boolean {
    return false;
  }

  public mcpToolCallResponseToMessage = (mcpToolResponse: MCPToolResponse, resp: MCPCallToolResponse, _model: Model) => {
    if ('toolUseId' in mcpToolResponse && mcpToolResponse.toolUseId) {
      return {
        role: 'user',
        parts: [{ text: !resp.isError ? resp.content : `Error: ${resp.content}` }]
      } satisfies Content;
    } else if ('toolCallId' in mcpToolResponse) {
      return {
        role: 'user',
        parts: [{
          functionResponse: {
            id: mcpToolResponse.toolCallId,
            name: mcpToolResponse.tool.id,
            response: {
              output: !resp.isError ? resp.content : undefined,
              error: resp.isError ? resp.content : undefined
            }
          }
        }]
      } satisfies Content;
    }
    return;
  }
}



// Gemini Providerå®ç°
export default class GeminiProvider extends BaseProvider {
  constructor(provider: any) {
    const model = {
      id: provider.models?.[0]?.id || 'gemini-pro',
      apiKey: provider.apiKey,
      baseUrl: provider.apiHost
    } as Model;
    super(model);
  }





  /**
   * è·å–æ¶ˆæ¯å†…å®¹ - ä½¿ç”¨ä¸“é—¨çš„æ¶ˆæ¯å†…å®¹æœåŠ¡
   */
  private async getMessageContents(message: Message): Promise<Content> {
    const messageContentService = createGeminiMessageContentService(this.model);
    return messageContentService.getMessageContents(message);
  }

  /**
   * è·å–æ¶ˆæ¯æ–‡æœ¬å†…å®¹ - æ¨¡æ‹Ÿçš„ getMainTextContent
   */
  protected async getMessageContent(message: Message): Promise<string> {
    return getMainTextContent(message);
  }

  /**
   * å¤„ç† Gemini Function Calling
   * 
   * å°† Gemini çš„ FunctionCall è½¬æ¢ä¸º MCP å·¥å…·è°ƒç”¨æ ¼å¼ï¼Œæ‰§è¡Œå·¥å…·å¹¶è¿”å›ç»“æœ
   */
  protected async processGeminiFunctionCalls(
    functionCalls: FunctionCall[],
    mcpTools: MCPTool[],
    onChunk?: (chunk: any) => void
  ): Promise<Content[]> {
    if (!functionCalls || functionCalls.length === 0) {
      return [];
    }

    console.log(`[Gemini] å¤„ç† ${functionCalls.length} ä¸ªå·¥å…·è°ƒç”¨`);

    // å°† Gemini FunctionCall è½¬æ¢ä¸º MCP å·¥å…·å“åº”æ ¼å¼
    const mcpToolResponses: GlobalMCPToolResponse[] = functionCalls.map((fc) => {
      const tool = mcpTools.find(t => {
        const toolName = (t.id || t.name).replace(/[^a-zA-Z0-9_.-]/g, '_');
        return toolName === fc.name || t.id === fc.name || t.name === fc.name;
      });
      
      const toolId = fc.id || `gemini_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
      
      return {
        id: toolId,
        toolCallId: toolId,
        tool: tool!,
        arguments: fc.args || {},
        status: 'pending' as const
      };
    }).filter(r => r.tool);

    if (mcpToolResponses.length === 0) {
      console.warn(`[Gemini] æ— æ³•åŒ¹é…ä»»ä½•å·¥å…·è°ƒç”¨`);
      return [];
    }

    // è°ƒç”¨å·¥å…·å¹¶è·å–ç»“æœ
    const results = await parseAndCallTools(
      mcpToolResponses,
      mcpTools,
      onChunk // ä¼ é€’ onChunk ä»¥å‘é€å·¥å…·æ‰§è¡ŒçŠ¶æ€äº‹ä»¶
    );

    // è½¬æ¢ç»“æœä¸º Gemini æ ¼å¼çš„æ¶ˆæ¯
    return results.map((result, index) => {
      const mcpResponse = mcpToolResponses[index];
      return {
        role: 'user',
        parts: [{
          functionResponse: {
            id: mcpResponse.toolCallId,
            name: mcpResponse.tool.id || mcpResponse.tool.name,
            response: {
              output: !result.isError ? result.content : undefined,
              error: result.isError ? result.content : undefined
            }
          }
        }]
      } as Content;
    });
  }



  /**
   * æ ¸å¿ƒcompletionsæ–¹æ³• - ä¸“æ³¨äºèŠå¤©åŠŸèƒ½
   * 
   * ============= æµå¼/éæµå¼è¾“å‡ºé“¾è·¯ =============
   * while (iteration < maxIterations) {
   *   1. å‘é€æ¶ˆæ¯ï¼Œè·å–å“åº”
   *   2. processStream å¤„ç†å“åº”ï¼š
   *      - å‘é€ THINKING_COMPLETE (å¦‚æœ‰)
   *      - å‘é€ TEXT_COMPLETE
   *      - æ”¶é›† functionCalls
   *   3. å¦‚æœæœ‰ functionCallsï¼š
   *      - processGeminiFunctionCalls æ‰§è¡Œå·¥å…·
   *      - å‘é€ MCP_TOOL_* åˆ›å»ºå·¥å…·å—
   *      - å°†ç»“æœæ·»åŠ åˆ° history
   *      - continue ä¸‹ä¸€è½®
   *   4. æ²¡æœ‰å·¥å…·è°ƒç”¨ â†’ å‘é€ BLOCK_COMPLETE â†’ break
   * }
   * 
   * ============= å…³é”®è®¾è®¡ =============
   * - æ‰€æœ‰ onChunk è°ƒç”¨éƒ½ awaitï¼Œé¿å…ç«æ€æ¡ä»¶
   * - å·¥å…·è°ƒç”¨å‰å…ˆå‘é€æ–‡æœ¬å—ï¼Œä¿è¯å—é¡ºåº
   * - æ”¯æŒå¤šè½®å·¥å…·è°ƒç”¨å¾ªç¯ï¼ˆæœ€å¤š 5 è½®ï¼‰
   */
  public async completions({
    messages,
    assistant,
    mcpTools,
    mcpMode = 'function',  // é»˜è®¤ä½¿ç”¨å‡½æ•°è°ƒç”¨æ¨¡å¼
    onChunk,
    onFilterMessages
  }: CompletionsParams): Promise<void> {
    const model = assistant.model || this.model;

    const { contextCount, maxTokens, streamOutput } = this.getAssistantSettings(assistant);

    // è¿‡æ»¤æ¶ˆæ¯ - å‚è€ƒå®ç°
    const userMessages = filterUserRoleStartMessages(
      filterEmptyMessages(takeRight(messages, contextCount + 2))
    );
    onFilterMessages(userMessages);

    const userLastMessage = userMessages.pop();
    const history: Content[] = [];

    for (const message of userMessages) {
      history.push(await this.getMessageContents(message));
    }

    let systemInstruction = assistant.prompt || '';
    
    // ğŸ”§ æ ¹æ® mcpMode å†³å®šä½¿ç”¨å“ªç§æ¨¡å¼
    const usePromptMode = mcpMode === 'prompt';
    let tools: Tool[] = [];
    
    if (mcpTools && mcpTools.length > 0) {
      if (usePromptMode) {
        // æç¤ºè¯æ³¨å…¥æ¨¡å¼ï¼šåªæ³¨å…¥ç³»ç»Ÿæç¤ºè¯ï¼Œä¸ä½¿ç”¨ Function Calling
        const mcpToolPrompt = getMCPSystemPrompt(mcpTools);
        if (mcpToolPrompt) {
          systemInstruction = systemInstruction + '\n\n' + mcpToolPrompt;
          console.log(`[GeminiProvider] æç¤ºè¯æ¨¡å¼ï¼šå·²æ³¨å…¥ ${mcpTools.length} ä¸ªå·¥å…·çš„æç¤ºè¯åˆ°ç³»ç»Ÿæç¤ºè¯`);
        }
        // tools ä¿æŒä¸ºç©ºæ•°ç»„
      } else {
        // å‡½æ•°è°ƒç”¨æ¨¡å¼ï¼šä½¿ç”¨ Function Calling API
        const toolsConfig = this.setupToolsConfig<Tool>({
          mcpTools,
          model,
          enableToolUse: true
        });
        tools = toolsConfig.tools;
        console.log(`[GeminiProvider] å‡½æ•°è°ƒç”¨æ¨¡å¼ï¼šä½¿ç”¨ ${tools.length} ä¸ªå·¥å…·`);
      }
    }

    //  è°ƒè¯•æ—¥å¿—ï¼šæ˜¾ç¤ºç³»ç»Ÿæç¤ºè¯çš„æœ€ç»ˆå¤„ç†ç»“æœ
    console.log(`[GeminiProvider.completions] ç³»ç»Ÿæç¤ºè¯æœ€ç»ˆå¤„ç†:`, {
      mcpMode,
      usePromptMode,
      mcpToolsCount: mcpTools?.length || 0,
      toolsCount: tools.length,
      assistantPrompt: assistant.prompt?.substring(0, 50) + (assistant.prompt?.length > 50 ? '...' : ''),
      systemInstruction: systemInstruction?.substring(0, 50) + (systemInstruction?.length > 50 ? '...' : ''),
      systemInstructionLength: systemInstruction?.length || 0,
      isGemmaModel: isGemmaModel(model)
    });

    // const toolResponses: MCPToolResponse[] = [];

    if (assistant.enableWebSearch && isWebSearchModel(model)) {
      tools.push({
        // @ts-ignore googleSearch is not a valid tool for Gemini
        googleSearch: {}
      });
    }

    // ä½¿ç”¨ GeminiConfigBuilder æ„å»ºé…ç½®
    const configBuilder = new GeminiConfigBuilder(assistant, model, maxTokens, systemInstruction, tools);
    const generateContentConfig = configBuilder.build();

    // æ·»åŠ è°ƒè¯•æ—¥å¿—æ˜¾ç¤ºä½¿ç”¨çš„å‚æ•°
    console.log(`[GeminiProvider] APIè¯·æ±‚å‚æ•°:`, {
      model: model.id,
      temperature: generateContentConfig.temperature,
      topP: generateContentConfig.topP,
      maxOutputTokens: generateContentConfig.maxOutputTokens,
      //  æ·»åŠ ç³»ç»Ÿæç¤ºè¯ä¿¡æ¯åˆ°æ—¥å¿—
      systemInstruction: typeof generateContentConfig.systemInstruction === 'string'
        ? generateContentConfig.systemInstruction.substring(0, 50) + (generateContentConfig.systemInstruction.length > 50 ? '...' : '')
        : generateContentConfig.systemInstruction ? '[Complex Content]' : '',
      systemInstructionLength: typeof generateContentConfig.systemInstruction === 'string'
        ? generateContentConfig.systemInstruction.length
        : 0,
      geminiSpecificParams: 'moved to configBuilder',
      assistantInfo: assistant ? {
        id: assistant.id,
        name: assistant.name,
        temperature: assistant.temperature,
        topP: assistant.topP
      } : 'æ— åŠ©æ‰‹ä¿¡æ¯'
    });

    const messageContents: Content = await this.getMessageContents(userLastMessage!);
    const chat = this.sdk.chats.create({
      model: model.id,
      config: generateContentConfig,
      history: history
    });

    // å¤„ç†Gemmaæ¨¡å‹çš„ç‰¹æ®Šæ ¼å¼
    if (isGemmaModel(model) && assistant.prompt) {
      const isFirstMessage = history.length === 0;
      if (isFirstMessage && messageContents) {
        const systemMessage = [{
          text: '<start_of_turn>user\n' + systemInstruction + '<end_of_turn>\n' +
                '<start_of_turn>user\n' + (messageContents?.parts?.[0] as Part).text + '<end_of_turn>'
        }] as Part[];
        if (messageContents && messageContents.parts) {
          messageContents.parts[0] = systemMessage[0];
        }
      }
    }

    const finalUsage = { completion_tokens: 0, prompt_tokens: 0, total_tokens: 0 };
    const finalMetrics = { completion_tokens: 0, time_completion_millsec: 0, time_first_token_millsec: 0 };
    const { cleanup, abortController } = this.createAbortController(userLastMessage?.id, true);

    // å¤„ç†æµå¼å“åº”çš„æ ¸å¿ƒé€»è¾‘
    // è¿”å› functionCalls ä»¥æ”¯æŒå¤šè½®å·¥å…·è°ƒç”¨å¾ªç¯
    const processStream = async (
      stream: AsyncGenerator<GenerateContentResponse> | GenerateContentResponse,
      _idx: number
    ): Promise<{ functionCalls: FunctionCall[]; textContent: string }> => {
      let functionCalls: FunctionCall[] = [];
      let time_first_token_millsec = 0;
      const start_time_millsec = new Date().getTime();
      let finalTextContent = '';

      if (stream instanceof GenerateContentResponse) {
        // éæµå¼å“åº”å¤„ç†
        // 
        // ============= éæµå¼è¾“å‡ºé“¾è·¯ =============
        // 1. å…ˆæ”¶é›†æ‰€æœ‰ thinking å’Œ text å†…å®¹
        // 2. æŒ‰æ­£ç¡®é¡ºåºå‘é€ï¼šTHINKING_COMPLETE â†’ TEXT_COMPLETE â†’ å·¥å…·å—
        // 3. æœ‰å·¥å…·è°ƒç”¨æ—¶å…ˆå‘é€æ–‡æœ¬å—ï¼Œå†å¤„ç†å·¥å…·
        // 4. æ‰€æœ‰ onChunk è°ƒç”¨éƒ½ awaitï¼Œé¿å…ç«æ€æ¡ä»¶

        const time_completion_millsec = new Date().getTime() - start_time_millsec;
        
        // æ”¶é›†å†…å®¹
        let thinkingContent = '';
        let textContent = '';
        
        console.log(`[Gemini processStream] éæµå¼å“åº” - candidatesæ•°é‡: ${stream.candidates?.length || 0}, stream.texté•¿åº¦: ${stream.text?.length || 0}`);
        
        stream.candidates?.forEach((candidate, candidateIdx) => {
          if (candidate.content) {
            history.push(candidate.content);
            console.log(`[Gemini processStream] candidate[${candidateIdx}] partsæ•°é‡: ${candidate.content.parts?.length || 0}`);
            candidate.content.parts?.forEach((part, partIdx) => {
              console.log(`[Gemini processStream] part[${partIdx}]:`, {
                hasText: !!part.text,
                textLength: part.text?.length || 0,
                thought: part.thought,
                hasFunctionCall: !!part.functionCall
              });
              if (part.functionCall) {
                functionCalls.push(part.functionCall);
              }
              if (part.thought && part.text) {
                thinkingContent += part.text;
              } else if (part.text) {
                textContent += part.text;
              }
            });
          }
        });
        
        // ä½¿ç”¨ stream.text ä½œä¸ºåå¤‡ï¼ˆå¦‚æœ parts æ²¡æœ‰æå–åˆ°æ–‡æœ¬ï¼‰
        if (!textContent && stream.text?.length) {
          console.log(`[Gemini processStream] ä½¿ç”¨ stream.text ä½œä¸ºåå¤‡æ–‡æœ¬`);
          textContent = stream.text;
        }
        
        finalTextContent = textContent;
        
        console.log(`[Gemini processStream] æœ€ç»ˆå†…å®¹ - thinking: ${thinkingContent.length}å­—ç¬¦, text: ${textContent.length}å­—ç¬¦`);
        
        // æŒ‰æ­£ç¡®é¡ºåºå‘é€ï¼šå…ˆ thinkingï¼Œå text
        if (thinkingContent) {
          console.log(`[Gemini processStream] å‘é€ THINKING_COMPLETE`);
          await onChunk({ type: ChunkType.THINKING_COMPLETE, text: thinkingContent, thinking_millsec: time_completion_millsec });
        }
        
        // æœ‰å·¥å…·è°ƒç”¨æ—¶ä¹Ÿè¦å‘é€æ–‡æœ¬å—ï¼ˆåœ¨å·¥å…·å—ä¹‹å‰ï¼‰
        if (textContent) {
          console.log(`[Gemini processStream] å‘é€ TEXT_COMPLETE`);
          await onChunk({ type: ChunkType.TEXT_COMPLETE, text: textContent });
        } else {
          console.log(`[Gemini processStream] æ²¡æœ‰æ–‡æœ¬å†…å®¹ï¼Œè·³è¿‡ TEXT_COMPLETE`);
        }

        // åªæœ‰åœ¨æ²¡æœ‰å·¥å…·è°ƒç”¨æ—¶æ‰å‘é€ BLOCK_COMPLETE
        if (functionCalls.length === 0) {
          await onChunk({
            type: ChunkType.BLOCK_COMPLETE,
            response: {
              text: stream.text,
              usage: {
                prompt_tokens: stream.usageMetadata?.promptTokenCount || 0,
                thoughts_tokens: stream.usageMetadata?.thoughtsTokenCount || 0,
                completion_tokens: stream.usageMetadata?.candidatesTokenCount || 0,
                total_tokens: stream.usageMetadata?.totalTokenCount || 0,
              },
              metrics: {
                completion_tokens: stream.usageMetadata?.candidatesTokenCount,
                time_completion_millsec,
                time_first_token_millsec: 0
              },
              webSearch: {
                results: stream.candidates?.[0]?.groundingMetadata,
                source: 'gemini'
              }
            }
          });
        }
      } else {
        // æµå¼å“åº”å¤„ç†
        // 
        // ============= æµå¼è¾“å‡ºé“¾è·¯ =============
        // 1. éå† chunksï¼Œç´¯ç§¯ thinking å’Œ text
        // 2. é‡åˆ° text ä¸”æœ‰ thinking æ—¶ï¼Œå…ˆå‘é€ THINKING_COMPLETE
        // 3. æ‰€æœ‰ onChunk è°ƒç”¨éƒ½ awaitï¼Œé¿å…ç«æ€æ¡ä»¶

        let content = '';
        let thinkingContent = '';
        let chunkIndex = 0;

        for await (const chunk of stream) {
          chunkIndex++;
          
          // æ£€æŸ¥ä¸­æ–­ä¿¡å·
          if (abortController.signal.aborted) {
            console.log('[GeminiProvider] æµå¼å“åº”è¢«ç”¨æˆ·ä¸­æ–­');
            break;
          }

          if (time_first_token_millsec == 0) {
            time_first_token_millsec = new Date().getTime();
          }

          const partsCount = chunk.candidates?.[0]?.content?.parts?.length || 0;
          console.log(`[Gemini æµå¼] chunk[${chunkIndex}] - partsæ•°é‡: ${partsCount}, finishReason: ${chunk.candidates?.[0]?.finishReason || 'none'}`);

          if (chunk.candidates?.[0]?.content?.parts && chunk.candidates[0].content.parts.length > 0) {
            const parts = chunk.candidates[0].content.parts;
            for (const part of parts) {
              console.log(`[Gemini æµå¼] part - thought: ${part.thought}, hasText: ${!!part.text}, textLen: ${part.text?.length || 0}`);
              
              if (!part.text) continue;

              if (part.thought) {
                // æ€è€ƒè¿‡ç¨‹
                if (time_first_token_millsec === 0) {
                  time_first_token_millsec = new Date().getTime();
                }
                thinkingContent += part.text;
                await onChunk({ type: ChunkType.THINKING_DELTA, text: part.text || '' });
              } else {
                // æ­£å¸¸å†…å®¹
                if (time_first_token_millsec == 0) {
                  time_first_token_millsec = new Date().getTime();
                }

                // å½“é‡åˆ°æ­£å¸¸æ–‡æœ¬ä¸”æœ‰æ€è€ƒå†…å®¹æ—¶ï¼Œå‘é€ THINKING_COMPLETE
                if (thinkingContent) {
                  console.log(`[Gemini æµå¼] å‘é€ THINKING_COMPLETE (${thinkingContent.length}å­—ç¬¦)`);
                  await onChunk({
                    type: ChunkType.THINKING_COMPLETE,
                    text: thinkingContent,
                    thinking_millsec: new Date().getTime() - time_first_token_millsec
                  });
                  thinkingContent = ''; // æ¸…ç©ºæ€ç»´å†…å®¹
                }

                content += part.text;
                await onChunk({ type: ChunkType.TEXT_DELTA, text: part.text });
              }
            }
          }

          if (chunk.candidates?.[0]?.finishReason) {
            console.log(`[Gemini æµå¼] å®Œæˆ - contenté•¿åº¦: ${content.length}, thinkingContenté•¿åº¦: ${thinkingContent.length}`);
            
            // ğŸ”§ ä¿®å¤ï¼šå¦‚æœåªæœ‰æ€è€ƒå†…å®¹æ²¡æœ‰æ™®é€šæ–‡æœ¬ï¼ŒæŠŠæ€è€ƒå†…å®¹ä½œä¸ºæ™®é€šæ–‡æœ¬å‘é€
            if (!content && thinkingContent) {
              console.log(`[Gemini æµå¼] åªæœ‰æ€è€ƒå†…å®¹ï¼Œä½œä¸ºæ™®é€šæ–‡æœ¬å‘é€`);
              content = thinkingContent;
              thinkingContent = '';
            }
            
            if (content) {
              console.log(`[Gemini æµå¼] å‘é€ TEXT_COMPLETE (${content.length}å­—ç¬¦)`);
              await onChunk({ type: ChunkType.TEXT_COMPLETE, text: content });
            }
            if (chunk.usageMetadata) {
              finalUsage.prompt_tokens += chunk.usageMetadata.promptTokenCount || 0;
              finalUsage.completion_tokens += chunk.usageMetadata.candidatesTokenCount || 0;
              finalUsage.total_tokens += chunk.usageMetadata.totalTokenCount || 0;
            }
            if (chunk.candidates?.[0]?.groundingMetadata) {
              const groundingMetadata = chunk.candidates?.[0]?.groundingMetadata;
              await onChunk({
                type: ChunkType.LLM_WEB_SEARCH_COMPLETE,
                llm_web_search: {
                  results: groundingMetadata,
                  source: 'gemini'
                }
              });
            }
            if (chunk.functionCalls) {
              chunk.candidates?.forEach((candidate) => {
                if (candidate.content) {
                  history.push(candidate.content);
                }
              });
              functionCalls = functionCalls.concat(chunk.functionCalls);
            }

            finalMetrics.completion_tokens = finalUsage.completion_tokens;
            finalMetrics.time_completion_millsec += new Date().getTime() - start_time_millsec;
            finalMetrics.time_first_token_millsec =
              (finalMetrics.time_first_token_millsec || 0) + (time_first_token_millsec - start_time_millsec);
          }
        }

        finalTextContent = content;

        // åªæœ‰åœ¨æ²¡æœ‰å·¥å…·è°ƒç”¨æ—¶æ‰å‘é€ BLOCK_COMPLETE
        if (functionCalls.length === 0) {
          await onChunk({
            type: ChunkType.BLOCK_COMPLETE,
            response: {
              usage: finalUsage,
              metrics: finalMetrics
            }
          });
        }
      }

      return { functionCalls, textContent: finalTextContent };
    };

    // ============= å¤šè½®å·¥å…·è°ƒç”¨å¾ªç¯ =============
    // ç±»ä¼¼ OpenAI provider çš„è®¾è®¡ï¼š
    // 1. å‘é€æ¶ˆæ¯ï¼Œè·å–å“åº”
    // 2. å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œæ‰§è¡Œå·¥å…·ï¼Œå°†ç»“æœæ·»åŠ åˆ° history
    // 3. é‡å¤ç›´åˆ°æ²¡æœ‰å·¥å…·è°ƒç”¨
    
    const maxIterations = 5;
    let iteration = 0;
    let currentMessage = messageContents;

    try {
      await onChunk({ type: ChunkType.LLM_RESPONSE_CREATED });

      while (iteration < maxIterations) {
        iteration++;
        console.log(`[Gemini] ç¬¬ ${iteration} è½®è¿­ä»£`);

        let response;
        if (!streamOutput) {
          // éæµå¼
          response = await withRetry(
            () => chat.sendMessage({
              message: currentMessage as PartUnion,
              config: {
                ...generateContentConfig,
                abortSignal: abortController.signal
              }
            }),
            'Gemini Non-Stream Request'
          );
        } else {
          // æµå¼
          response = await withRetry(
            () => chat.sendMessageStream({
              message: currentMessage as PartUnion,
              config: {
                ...generateContentConfig,
                abortSignal: abortController.signal
              }
            }),
            'Gemini Stream Request'
          );
        }

        // å¤„ç†å“åº”
        const { functionCalls, textContent } = await processStream(response, iteration - 1);

        // å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œå¤„ç†å®ƒä»¬
        if (functionCalls.length > 0 && mcpTools.length > 0) {
          console.log(`[Gemini] ç¬¬ ${iteration} è½®æ£€æµ‹åˆ° ${functionCalls.length} ä¸ªå·¥å…·è°ƒç”¨`);
          
          // æ‰§è¡Œå·¥å…·è°ƒç”¨
          const toolResults = await this.processGeminiFunctionCalls(functionCalls, mcpTools, onChunk);
          
          if (toolResults.length > 0) {
            // å°†å·¥å…·ç»“æœæ·»åŠ åˆ°å†å²
            history.push(...toolResults);
            
            // å‡†å¤‡ä¸‹ä¸€è½®çš„æ¶ˆæ¯ï¼ˆç©ºæ¶ˆæ¯ï¼Œè®©æ¨¡å‹ç»§ç»­ï¼‰
            currentMessage = { role: 'user', parts: [{ text: 'è¯·æ ¹æ®å·¥å…·æ‰§è¡Œç»“æœç»§ç»­å›ç­”ã€‚' }] } as Content;
            
            continue; // ç»§ç»­ä¸‹ä¸€è½®
          }
        }

        // æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œå‘é€ BLOCK_COMPLETE å¹¶ç»“æŸ
        await onChunk({
          type: ChunkType.BLOCK_COMPLETE,
          response: {
            text: textContent,
            usage: { prompt_tokens: 0, completion_tokens: 0, total_tokens: 0 },
            metrics: { completion_tokens: 0, time_completion_millsec: 0, time_first_token_millsec: 0 }
          }
        });
        break;
      }
    } finally {
      cleanup();
    }
  }





  /**
   * ç¿»è¯‘æ–¹æ³•
   */
  public async translate(
    content: string,
    assistant: any,
    onResponse?: (text: string, isComplete: boolean) => void,
    abortSignal?: AbortSignal
  ) {
    const model = assistant.model || this.model;
    const { maxTokens } = this.getAssistantSettings(assistant);

    const _content = isGemmaModel(model) && assistant.prompt
      ? `<start_of_turn>user\n${assistant.prompt}<end_of_turn>\n<start_of_turn>user\n${content}<end_of_turn>`
      : content;

    // ä½¿ç”¨ GeminiConfigBuilder æ„å»ºé…ç½®
    const configBuilder = new GeminiConfigBuilder(assistant, model, maxTokens, assistant.prompt, []);
    const config = configBuilder.build();

    if (!onResponse) {
      const response = await withRetry(
        () => this.sdk.models.generateContent({
          model: model.id,
          config: config,
          contents: [{ role: 'user', parts: [{ text: _content }] }]
        }),
        'Gemini Translate'
      );
      return response.text || '';
    }

    const response = await withRetry(
      () => this.sdk.models.generateContentStream({
        model: model.id,
        config: config,
        contents: [{ role: 'user', parts: [{ text: content }] }]
      }),
      'Gemini Translate Stream'
    );

    let text = '';
    for await (const chunk of response) {
      // æ£€æŸ¥ä¸­æ–­ä¿¡å·
      if (abortSignal?.aborted) {
        console.log('[GeminiProvider.translate] æµå¼å“åº”è¢«ç”¨æˆ·ä¸­æ–­');
        break;
      }

      text += chunk.text;
      onResponse?.(text, false);
    }
    onResponse?.(text, true);
    return text;
  }

  /**
   * ç”Ÿæˆæ‘˜è¦
   */
  public async summaries(messages: Message[], assistant: any): Promise<string> {
    const model = assistant.model || this.model;
    const userMessages = takeRight(messages, 5)
      .filter((message) => !message.isPreset)
      .map((message) => ({
        role: message.role,
        content: getMainTextContent(message)
      }));

    const userMessageContent = userMessages.reduce((prev, curr) => {
      const content = curr.role === 'user' ? `User: ${curr.content}` : `Assistant: ${curr.content}`;
      return prev + (prev ? '\n' : '') + content;
    }, '');

    const systemMessage = {
      role: 'system',
      content: 'è¯·ä¸ºä»¥ä¸‹å¯¹è¯ç”Ÿæˆä¸€ä¸ªç®€æ´çš„æ ‡é¢˜'
    };

    const userMessage = { role: 'user', content: userMessageContent };
    const content = isGemmaModel(model)
      ? `<start_of_turn>user\n${systemMessage.content}<end_of_turn>\n<start_of_turn>user\n${userMessage.content}<end_of_turn>`
      : userMessage.content;

    // ä½¿ç”¨ GeminiConfigBuilder æ„å»ºé…ç½®
    const configBuilder = new GeminiConfigBuilder(assistant, model, 4096, systemMessage.content, []);
    const config = configBuilder.build();

    const response = await this.sdk.models.generateContent({
      model: model.id,
      config: config,
      contents: [{ role: 'user', parts: [{ text: content }] }]
    });

    return response.text || '';
  }

  /**
   * ç”Ÿæˆæ–‡æœ¬
   */
  public async generateText({ prompt, content }: { prompt: string; content: string }): Promise<string> {
    const model = this.model;
    const MessageContent = isGemmaModel(model)
      ? `<start_of_turn>user\n${prompt}<end_of_turn>\n<start_of_turn>user\n${content}<end_of_turn>`
      : content;

    // åˆ›å»ºä¸´æ—¶åŠ©æ‰‹å¯¹è±¡ç”¨äºé…ç½®æ„å»º
    const tempAssistant = { prompt: prompt };

    // ä½¿ç”¨ GeminiConfigBuilder æ„å»ºé…ç½®
    const configBuilder = new GeminiConfigBuilder(tempAssistant, model, 4096, prompt, []);
    const config = configBuilder.build();

    const response = await this.sdk.models.generateContent({
      model: model.id,
      config: config,
      contents: [{ role: 'user', parts: [{ text: MessageContent }] }]
    });

    return response.text || '';
  }

  /**
   * ç”Ÿæˆå»ºè®®
   */
  public async suggestions(): Promise<any[]> {
    return [];
  }

  /**
   * æœç´¢æ‘˜è¦
   */
  public async summaryForSearch(messages: Message[], assistant: any): Promise<string> {
    const model = assistant.model || this.model;
    const systemMessage = { role: 'system', content: assistant.prompt };
    const userMessageContent = messages.map(getMainTextContent).join('\n');

    const content = isGemmaModel(model)
      ? `<start_of_turn>user\n${systemMessage.content}<end_of_turn>\n<start_of_turn>user\n${userMessageContent}<end_of_turn>`
      : userMessageContent;

    const lastUserMessage = messages[messages.length - 1];
    const { abortController, cleanup } = this.createAbortController(lastUserMessage?.id);
    const { signal } = abortController;

    // ä½¿ç”¨ GeminiConfigBuilder æ„å»ºé…ç½®
    const configBuilder = new GeminiConfigBuilder(assistant, model, 4096, systemMessage.content, []);
    const config = configBuilder.build();

    // æ·»åŠ ç‰¹å®šçš„é…ç½®é¡¹
    const finalConfig = {
      ...config,
      httpOptions: { timeout: 20 * 1000 },
      abortSignal: signal
    };

    const response = await this.sdk.models
      .generateContent({
        model: model.id,
        config: finalConfig,
        contents: [{ role: 'user', parts: [{ text: content }] }]
      })
      .finally(cleanup);

    return response.text || '';
  }

  /**
   * ç”Ÿæˆå›¾åƒ
   */
  public async generateImage(): Promise<string[]> {
    return [];
  }

  /**
   * æ£€æŸ¥æ¨¡å‹æœ‰æ•ˆæ€§
   */
  public async check(model: Model, stream: boolean = false): Promise<{ valid: boolean; error: Error | null }> {
    if (!model) {
      return { valid: false, error: new Error('No model found') };
    }

    // ä½¿ç”¨ GeminiConfigBuilder æ„å»ºé…ç½®ï¼Œä½†è®¾ç½®æœ€å°çš„ maxTokens ç”¨äºæµ‹è¯•
    const testAssistant = {
      enableThinking: false,
      thinkingBudget: 0
    };
    const configBuilder = new GeminiConfigBuilder(testAssistant, model, 1, undefined, []);
    const config = configBuilder.build();

    try {
      if (!stream) {
        const result = await this.sdk.models.generateContent({
          model: model.id,
          contents: [{ role: 'user', parts: [{ text: 'hi' }] }],
          config: config
        });
        if (!result.text) {
          throw new Error('Empty response');
        }
      } else {
        const response = await this.sdk.models.generateContentStream({
          model: model.id,
          contents: [{ role: 'user', parts: [{ text: 'hi' }] }],
          config: config
        });
        let hasContent = false;
        for await (const chunk of response) {
          if (chunk.candidates && chunk.candidates[0].finishReason === FinishReason.MAX_TOKENS) {
            hasContent = true;
            break;
          }
        }
        if (!hasContent) {
          throw new Error('Empty streaming response');
        }
      }
      return { valid: true, error: null };
    } catch (error: any) {
      return { valid: false, error };
    }
  }



  /**
   * è·å–æ–‡æœ¬åµŒå…¥
   */
  public async getEmbedding(
    text: string,
    options?: {
      taskType?: 'RETRIEVAL_QUERY' | 'RETRIEVAL_DOCUMENT' | 'SEMANTIC_SIMILARITY' | 'CLASSIFICATION' | 'CLUSTERING';
      title?: string;
    }
  ): Promise<number[]> {
    const embeddingService = createGeminiEmbeddingService(this.model);
    const result = await embeddingService.getEmbedding({
      text,
      model: this.model,
      taskType: options?.taskType,
      title: options?.title
    });
    return result.embedding;
  }

  /**
   * è·å–åµŒå…¥ç»´åº¦
   */
  public async getEmbeddingDimensions(model: Model): Promise<number> {
    const embeddingService = createGeminiEmbeddingService(model);
    return embeddingService.getEmbeddingDimensions(model);
  }

  /**
   * å…¼å®¹æ€§æ–¹æ³•ï¼šsendChatMessage - è½¬æ¢ä¸ºcompletionsè°ƒç”¨
   * 
   * ğŸ”§ ä¿®å¤ï¼šç›´æ¥è°ƒç”¨ completions æ–¹æ³•ï¼Œå¤ç”¨å·¥å…·å¤„ç†é€»è¾‘
   */
  public async sendChatMessage(
    messages: Message[],
    options?: {
      onChunk?: (chunk: any) => void;
      enableWebSearch?: boolean;
      enableThinking?: boolean;
      enableTools?: boolean;
      mcpTools?: MCPTool[];
      mcpMode?: 'prompt' | 'function';
      systemPrompt?: string;
      abortSignal?: AbortSignal;
      assistant?: any;
    }
  ): Promise<string | { content: string; reasoning?: string; reasoningTime?: number }> {
    // ğŸ”§ ä¿®å¤ï¼šæ­£ç¡®å¤„ç† streamOutput è®¾ç½®
    // ä»ä¼ å…¥çš„ assistant ä¸­è¯»å–ï¼Œæ”¯æŒå¤šç§ä½ç½®
    const inputAssistant = options?.assistant;
    const streamOutputSetting = inputAssistant?.settings?.streamOutput ?? inputAssistant?.streamOutput;
    const streamOutput = streamOutputSetting !== false;
    
    console.log(`[GeminiProvider.sendChatMessage] streamOutput æ£€æµ‹:`, {
      'inputAssistant?.settings?.streamOutput': inputAssistant?.settings?.streamOutput,
      'inputAssistant?.streamOutput': inputAssistant?.streamOutput,
      'streamOutputSetting': streamOutputSetting,
      'streamOutput (final)': streamOutput
    });
    
    // æ„å»º assistant å¯¹è±¡
    const assistant = inputAssistant ? {
      ...inputAssistant,
      settings: {
        ...inputAssistant.settings,
        streamOutput: streamOutput  // ç¡®ä¿ streamOutput æ­£ç¡®è®¾ç½®
      }
    } : {
      model: this.model,
      prompt: options?.systemPrompt || '',
      settings: {
        streamOutput: streamOutput
      },
      enableWebSearch: options?.enableWebSearch || false,
      enableGenerateImage: false
    };

    // å¦‚æœæœ‰ä¼ å…¥çš„ assistant ä½†æ²¡æœ‰ promptï¼Œä½¿ç”¨ systemPrompt
    if (inputAssistant && options?.systemPrompt && !inputAssistant.prompt) {
      assistant.prompt = options.systemPrompt;
    }

    console.log(`[GeminiProvider.sendChatMessage] è°ƒç”¨ completions - mcpTools: ${options?.mcpTools?.length || 0}, mcpMode: ${options?.mcpMode || 'function'}, streamOutput: ${streamOutput}`);

    // æ”¶é›†å“åº”å†…å®¹
    let content = '';
    let reasoning = '';
    let reasoningTime = 0;

    // ğŸ”§ ä¿®å¤ï¼šç›´æ¥è°ƒç”¨ completions æ–¹æ³•ï¼Œå¤ç”¨æ‰€æœ‰å·¥å…·å¤„ç†é€»è¾‘
    await this.completions({
      messages,
      assistant,
      mcpTools: options?.mcpTools || [],
      mcpMode: options?.mcpMode || 'function',
      onChunk: (chunk: any) => {
        // è½¬å‘ chunk å¹¶æ”¶é›†å†…å®¹
        if (chunk.type === ChunkType.TEXT_DELTA) {
          content += chunk.text || '';
        } else if (chunk.type === ChunkType.TEXT_COMPLETE) {
          content = chunk.text || content;
        } else if (chunk.type === ChunkType.THINKING_DELTA) {
          reasoning += chunk.text || '';
        } else if (chunk.type === ChunkType.THINKING_COMPLETE) {
          reasoning = chunk.text || reasoning;
          reasoningTime = chunk.thinking_millsec || 0;
        }
        
        // è½¬å‘ç»™å¤–éƒ¨ onChunk
        options?.onChunk?.(chunk);
      },
      onFilterMessages: () => {}
    });

    return { content, reasoning, reasoningTime };
  }

  /**
   * å…¼å®¹æ€§æ–¹æ³•ï¼štestConnection
   */
  public async testConnection(): Promise<boolean> {
    return testConnection(this.model);
  }

  /**
   * å…¼å®¹æ€§æ–¹æ³•ï¼šgetModels
   */
  public async getModels(): Promise<any[]> {
    return fetchModels(this.model);
  }
}

// åŒæ—¶æä¾›å‘½åå¯¼å‡ºä»¥ç¡®ä¿å…¼å®¹æ€§
export { GeminiProvider };
