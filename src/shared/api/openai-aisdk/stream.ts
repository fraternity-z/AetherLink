/**
 * AI SDK æµå¼å“åº”æ¨¡å—
 * ä½¿ç”¨ @ai-sdk/openai çš„ streamText å®ç°æµå¼å“åº”
 * æ”¯æŒæ¨ç†å†…å®¹ã€å·¥å…·è°ƒç”¨ã€<think> æ ‡ç­¾è§£æ
 */
import { streamText, generateText } from 'ai';
import type { OpenAIProvider as AISDKOpenAIProvider } from '@ai-sdk/openai';
import { logApiRequest } from '../../services/infra/LoggerService';
import { EventEmitter, EVENT_NAMES } from '../../services/infra/EventEmitter';
import { hasToolUseTags } from '../../utils/mcpToolParser';
import { ChunkType, type Chunk } from '../../types/chunk';
import { getAppropriateTag, type ReasoningTag, DEFAULT_REASONING_TAGS } from '../../config/reasoningTags';
import type { Model, MCPTool } from '../../types';
import type { ModelProvider } from '../../config/defaultModels';
import { convertMcpToolsToAISDK } from './tools';
import store from '../../store';

/**
 * è·å–æ¨¡å‹å¯¹åº”çš„ä¾›åº”å•†é…ç½®
 */
function getProviderConfig(model: Model): ModelProvider | null {
  try {
    const state = store.getState();
    const providers = state.settings?.providers;

    if (!providers || !Array.isArray(providers)) {
      return null;
    }

    // æ ¹æ®æ¨¡å‹çš„ provider å­—æ®µæŸ¥æ‰¾å¯¹åº”çš„ä¾›åº”å•†
    const provider = providers.find((p: ModelProvider) => p.id === model.provider);
    return provider || null;
  } catch (error) {
    console.error('[AI SDK Stream] è·å–ä¾›åº”å•†é…ç½®å¤±è´¥:', error);
    return null;
  }
}

/**
 * æµå¼å“åº”ç»“æœç±»å‹
 */
export interface StreamResult {
  content: string;
  reasoning?: string;
  reasoningTime?: number;
  hasToolCalls?: boolean;
  nativeToolCalls?: any[];
}

/**
 * æµå¼è¯·æ±‚å‚æ•°
 */
export interface StreamParams {
  messages?: any[];
  temperature?: number;
  max_tokens?: number;
  top_p?: number;
  tools?: any[];
  tool_choice?: any;
  signal?: AbortSignal;
  enableTools?: boolean;
  mcpTools?: MCPTool[];
  mcpMode?: 'prompt' | 'function';
  model?: Model;
  /** è‡ªå®šä¹‰è¯·æ±‚ä½“å‚æ•°ï¼ˆä¼˜å…ˆçº§ï¼šæ¨¡å‹çº§åˆ« > ä¾›åº”å•†çº§åˆ«ï¼‰ */
  extraBody?: Record<string, any>;
  /** æ˜¯å¦ä½¿ç”¨ Responses APIï¼ˆä»…å¯¹ OpenAI å®˜æ–¹ API æœ‰æ•ˆï¼‰ */
  useResponsesAPI?: boolean;
}

/**
 * è§£ææ¨ç†æ ‡ç­¾å†…å®¹
 * æ”¯æŒåŠ¨æ€é…ç½®çš„å¼€å§‹/ç»“æŸæ ‡ç­¾
 */
class ThinkTagParser {
  private contentBuffer = '';
  private isInThinkTag = false;
  private thinkBuffer = '';
  private reasoningStartTime = 0;
  private hasReasoningContent = false;
  private openingTag: string;
  private closingTag: string;

  constructor(tag?: ReasoningTag) {
    // æ”¯æŒåŠ¨æ€é…ç½®çš„æ¨ç†æ ‡ç­¾
    this.openingTag = tag?.openingTag || '<think>';
    this.closingTag = tag?.closingTag || '</think>';
  }

  /**
   * å¤„ç†æ–‡æœ¬å—
   * @returns { normalText: string, thinkText: string, isThinking: boolean }
   */
  processChunk(text: string): { normalText: string; thinkText: string; isThinking: boolean } {
    this.contentBuffer += text;
    
    let normalText = '';
    let thinkText = '';
    let processedAny = true;

    while (processedAny && this.contentBuffer.length > 0) {
      processedAny = false;

      if (!this.isInThinkTag) {
        // æŸ¥æ‰¾å¼€å§‹æ ‡ç­¾
        const thinkStartIndex = this.contentBuffer.indexOf(this.openingTag);
        if (thinkStartIndex !== -1) {
          // å¤„ç†å¼€å§‹æ ‡ç­¾ä¹‹å‰çš„æ™®é€šå†…å®¹
          normalText += this.contentBuffer.substring(0, thinkStartIndex);
          
          // è¿›å…¥æ€è€ƒæ¨¡å¼
          this.isInThinkTag = true;
          if (!this.hasReasoningContent) {
            this.hasReasoningContent = true;
            this.reasoningStartTime = Date.now();
          }
          
          this.contentBuffer = this.contentBuffer.substring(thinkStartIndex + this.openingTag.length);
          processedAny = true;
        } else if (this.contentBuffer.length > this.openingTag.length + 5) {
          // æ²¡æœ‰æ‰¾åˆ°å¼€å§‹æ ‡ç­¾ï¼Œè¾“å‡ºå®‰å…¨çš„å†…å®¹
          const safeLength = this.contentBuffer.length - (this.openingTag.length + 5);
          const safeContent = this.contentBuffer.substring(0, safeLength);
          normalText += safeContent;
          this.contentBuffer = this.contentBuffer.substring(safeLength);
          processedAny = true;
        }
      } else {
        // åœ¨æ€è€ƒæ ‡ç­¾å†…ï¼ŒæŸ¥æ‰¾ç»“æŸæ ‡ç­¾
        const thinkEndIndex = this.contentBuffer.indexOf(this.closingTag);
        if (thinkEndIndex !== -1) {
          // å¤„ç†æ€è€ƒå†…å®¹
          thinkText += this.contentBuffer.substring(0, thinkEndIndex);
          this.thinkBuffer += this.contentBuffer.substring(0, thinkEndIndex);
          
          // é€€å‡ºæ€è€ƒæ¨¡å¼
          this.isInThinkTag = false;
          this.contentBuffer = this.contentBuffer.substring(thinkEndIndex + this.closingTag.length);
          processedAny = true;
        } else if (this.contentBuffer.length > this.closingTag.length + 5) {
          // æ²¡æœ‰æ‰¾åˆ°ç»“æŸæ ‡ç­¾ï¼Œè¾“å‡ºå®‰å…¨çš„æ€è€ƒå†…å®¹
          const safeLength = this.contentBuffer.length - (this.closingTag.length + 5);
          const safeThinkContent = this.contentBuffer.substring(0, safeLength);
          thinkText += safeThinkContent;
          this.thinkBuffer += safeThinkContent;
          this.contentBuffer = this.contentBuffer.substring(safeLength);
          processedAny = true;
        }
      }
    }

    return { normalText, thinkText, isThinking: this.isInThinkTag };
  }

  /**
   * æµç»“æŸæ—¶å¤„ç†å‰©ä½™å†…å®¹
   */
  flush(): { normalText: string; thinkText: string } {
    let normalText = '';
    let thinkText = '';

    if (this.contentBuffer.length > 0) {
      if (this.isInThinkTag) {
        thinkText = this.contentBuffer;
        this.thinkBuffer += this.contentBuffer;
      } else {
        normalText = this.contentBuffer;
      }
      this.contentBuffer = '';
    }

    return { normalText, thinkText };
  }

  getFullThinkContent(): string {
    return this.thinkBuffer;
  }

  getReasoningTime(): number {
    return this.hasReasoningContent ? Date.now() - this.reasoningStartTime : 0;
  }
}

/**
 * AI SDK ç»Ÿä¸€æµå¼å“åº”å‡½æ•°
 * ä¸åŸæœ‰ unifiedStreamCompletion æ¥å£ä¿æŒä¸€è‡´
 */
export async function streamCompletion(
  client: AISDKOpenAIProvider,
  modelId: string,
  messages: any[],
  temperature?: number,
  maxTokens?: number,
  additionalParams?: StreamParams,
  onChunk?: (chunk: Chunk) => void
): Promise<StreamResult> {
  console.log(`[AI SDK Stream] å¼€å§‹æµå¼å“åº”, æ¨¡å‹: ${modelId}`);

  const startTime = Date.now();
  const signal = additionalParams?.signal;
  const model = additionalParams?.model;
  const mcpTools = additionalParams?.mcpTools || [];
  const mcpMode = additionalParams?.mcpMode || 'function';
  const enableTools = additionalParams?.enableTools !== false;

  // è·å– extraBodyï¼ˆä¼˜å…ˆçº§ï¼šæ¨¡å‹çº§åˆ« > ä¾›åº”å•†çº§åˆ«ï¼‰
  const extraBody = additionalParams?.extraBody || 
                    (model as any)?.extraBody || 
                    (model as any)?.providerExtraBody;

  // è·å– Responses API å¼€å…³é…ç½®ï¼ˆä¼˜å…ˆçº§ï¼šä¾›åº”å•†é…ç½® > æ¨¡å‹é…ç½® > é»˜è®¤å…³é—­ï¼‰
  const providerConfig = model ? getProviderConfig(model) : null;
  const useResponsesAPI = providerConfig?.useResponsesAPI || 
                          additionalParams?.useResponsesAPI || 
                          (model as any)?.useResponsesAPI || 
                          false;

  // è·å–æ¨ç†æ ‡ç­¾é…ç½®ï¼ˆæ ¹æ®æ¨¡å‹åŠ¨æ€é€‰æ‹©ï¼‰
  const reasoningTag = model ? getAppropriateTag(model) : DEFAULT_REASONING_TAGS[0];

  try {
    // å‡†å¤‡æ¶ˆæ¯ - è½¬æ¢å¤šæ¨¡æ€å†…å®¹æ ¼å¼
    const processedMessages = messages.map(msg => {
      const role = msg.role as 'system' | 'user' | 'assistant';
      let content = msg.content;
      
      // å¤„ç†å¤šæ¨¡æ€æ¶ˆæ¯å†…å®¹ï¼ˆOpenAI æ ¼å¼ -> AI SDK æ ¼å¼ï¼‰
      if (Array.isArray(content)) {
        content = content.map((part: any) => {
          // OpenAI æ ¼å¼çš„å›¾ç‰‡: { type: 'image_url', image_url: { url: '...' } }
          // AI SDK æ ¼å¼: { type: 'image', image: '...' }
          if (part.type === 'image_url' && part.image_url?.url) {
            return {
              type: 'image',
              image: part.image_url.url,
              ...(part.image_url.detail && { providerOptions: { openai: { imageDetail: part.image_url.detail } } })
            };
          }
          // æ–‡æœ¬éƒ¨åˆ†ä¿æŒä¸å˜
          if (part.type === 'text') {
            return { type: 'text', text: part.text };
          }
          // å…¶ä»–æ ¼å¼ç›´æ¥è¿”å›
          return part;
        });
      }
      
      return { role, content };
    });

    // è®°å½• API è¯·æ±‚
    logApiRequest('AI SDK OpenAI Stream', 'INFO', {
      provider: 'openai-aisdk',
      model: modelId,
      messageCount: processedMessages.length,
      temperature,
      maxTokens,
      extraBody: extraBody ? Object.keys(extraBody) : undefined,
      timestamp: Date.now()
    });

    // å‡†å¤‡å·¥å…·é…ç½®ï¼ˆä»…åœ¨å‡½æ•°è°ƒç”¨æ¨¡å¼ä¸‹ï¼‰
    let tools: any = undefined;
    if (enableTools && mcpTools.length > 0 && mcpMode === 'function') {
      tools = convertMcpToolsToAISDK(mcpTools);
      console.log(`[AI SDK Stream] å¯ç”¨ ${Object.keys(tools).length} ä¸ªå·¥å…·`);
    }

    // ğŸ›¡ï¸ Prompt æ¨¡å¼é˜²å¹»è§‰ï¼šæ·»åŠ  stopSequences
    // å½“å·¥å…·é€šè¿‡ç³»ç»Ÿæç¤ºè¯æ³¨å…¥ï¼ˆéåŸç”Ÿå‡½æ•°è°ƒç”¨ï¼‰æ—¶ï¼Œæ¨¡å‹å¯èƒ½åœ¨ </tool_use> å
    // ç»§ç»­ç”Ÿæˆ <tool_use_result> å¹»è§‰å†…å®¹ã€‚æ·»åŠ  stop sequence å¼ºåˆ¶æ¨¡å‹åœæ­¢ï¼Œ
    // è®©å¤šè½®å¾ªç¯ï¼ˆprovider.ts while loopï¼‰çœŸæ­£å‘æŒ¥ä½œç”¨
    const isPromptMode = !enableTools && mcpTools.length > 0;
    const stopSequences = isPromptMode ? ['<tool_use_result'] : undefined;

    // å‡†å¤‡ providerOptionsï¼ˆç”¨äºä¼ é€’ extraBodyï¼‰
    let providerOptions: Record<string, any> | undefined;
    if (extraBody && typeof extraBody === 'object' && Object.keys(extraBody).length > 0) {
      providerOptions = {
        openai: extraBody
      };
      console.log(`[AI SDK Stream] åˆå¹¶è‡ªå®šä¹‰è¯·æ±‚ä½“å‚æ•°: ${Object.keys(extraBody).join(', ')}`);
    }

    // æ ¹æ® useResponsesAPI å¼€å…³é€‰æ‹© API ç±»å‹
    // - client.chat(modelId): Chat Completions APIï¼ˆé»˜è®¤ï¼Œå…¼å®¹å¤§å¤šæ•° OpenAI å…¼å®¹æœåŠ¡ï¼‰
    // - client.responses(modelId): Responses APIï¼ˆä»… OpenAI å®˜æ–¹æ”¯æŒï¼‰
    const modelInstance = useResponsesAPI 
      ? client.responses(modelId)  // Responses API
      : client.chat(modelId);       // Chat Completions API

    console.log(`[AI SDK Stream] ä½¿ç”¨ ${useResponsesAPI ? 'Responses' : 'Chat Completions'} API`);

    const result = await streamText({
      model: modelInstance,
      messages: processedMessages,
      ...(temperature !== undefined && { temperature }),
      ...(maxTokens !== undefined && { maxTokens }),
      abortSignal: signal,
      ...(tools && { tools }),
      ...(providerOptions && { providerOptions }),
      ...(stopSequences && { stopSequences }),
      // å¯ç”¨åŸå§‹ chunk è¾“å‡ºï¼Œç”¨äºæå–ç¬¬ä¸‰æ–¹ API çš„ reasoning_content å­—æ®µ
      includeRawChunks: true,
    });

    // è§£æå™¨ - ä½¿ç”¨åŠ¨æ€é…ç½®çš„æ¨ç†æ ‡ç­¾
    const thinkParser = new ThinkTagParser(reasoningTag);
    let fullContent = '';
    let fullReasoning = '';
    const toolCalls: any[] = [];

    // å¤„ç†æµå¼å“åº”
    for await (const part of result.fullStream) {
      switch (part.type) {
        case 'text-delta':
          // è§£æ <think> æ ‡ç­¾ - AI SDK v6 ä½¿ç”¨ text å±æ€§
          const textContent = (part as any).text || (part as any).textDelta || '';
          const { normalText, thinkText } = thinkParser.processChunk(textContent);
          
          // â­ ç´¯ç§¯æ¨¡å¼ï¼šå‘é€å®Œæ•´ç´¯ç§¯å†…å®¹ï¼ˆå‚è€ƒ Cherry Studioï¼‰
          if (normalText) {
            fullContent += normalText;
            onChunk?.({ type: ChunkType.TEXT_DELTA, text: fullContent });  // å‘é€ç´¯ç§¯å†…å®¹
          }
          
          if (thinkText) {
            fullReasoning += thinkText;
            onChunk?.({
              type: ChunkType.THINKING_DELTA,
              text: fullReasoning,  // å‘é€ç´¯ç§¯å†…å®¹
              thinking_millsec: thinkParser.getReasoningTime()
            });
          }
          break;

        case 'tool-call':
          console.log(`[AI SDK Stream] æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨: ${part.toolName}`);
          // AI SDK v6 ä½¿ç”¨ input è€Œä¸æ˜¯ args
          const toolInput = (part as any).input || (part as any).args || {};
          toolCalls.push({
            id: part.toolCallId,
            type: 'function',
            function: {
              name: part.toolName,
              arguments: JSON.stringify(toolInput)
            }
          });
          
          // ä½¿ç”¨ MCP_TOOL_CREATED ç±»å‹
          onChunk?.({
            type: ChunkType.MCP_TOOL_CREATED,
            responses: [{
              id: part.toolCallId,
              name: part.toolName,
              arguments: toolInput,
              status: 'pending'
            }]
          });
          break;

        case 'reasoning-delta':
          // AI SDK åŸç”Ÿæ¨ç†å†…å®¹ï¼ˆå¦‚ o1 æ¨¡å‹ï¼‰
          const reasoningText = (part as any).text || (part as any).textDelta || '';
          if (reasoningText) {
            fullReasoning += reasoningText;
            onChunk?.({
              type: ChunkType.THINKING_DELTA,
              text: fullReasoning,  // â­ å‘é€ç´¯ç§¯å†…å®¹
              thinking_millsec: Date.now() - startTime
            });
          }
          break;

        case 'raw':
          // å¤„ç†åŸå§‹ chunk æ•°æ®ï¼Œæå–ç¬¬ä¸‰æ–¹ API çš„ reasoning_content å­—æ®µ
          // è¿™æ˜¯ OpenAI å…¼å®¹ APIï¼ˆå¦‚ Geminiã€DeepSeek ç­‰ï¼‰è¿”å›æ€è€ƒå†…å®¹çš„æ–¹å¼
          try {
            const rawChunk = (part as any).rawValue || (part as any).chunk;
            if (rawChunk?.choices?.[0]?.delta?.reasoning_content) {
              const rawReasoningContent = rawChunk.choices[0].delta.reasoning_content;
              if (rawReasoningContent && typeof rawReasoningContent === 'string') {
                fullReasoning += rawReasoningContent;
                onChunk?.({
                  type: ChunkType.THINKING_DELTA,
                  text: fullReasoning,  // â­ å‘é€ç´¯ç§¯å†…å®¹
                  thinking_millsec: Date.now() - startTime
                });
              }
            }
            // åŒæ—¶æ£€æŸ¥ message.reasoning_contentï¼ˆéæµå¼æ ¼å¼ï¼‰
            if (rawChunk?.choices?.[0]?.message?.reasoning_content) {
              const msgReasoningContent = rawChunk.choices[0].message.reasoning_content;
              if (msgReasoningContent && typeof msgReasoningContent === 'string' && !fullReasoning.includes(msgReasoningContent)) {
                fullReasoning += msgReasoningContent;
                onChunk?.({
                  type: ChunkType.THINKING_DELTA,
                  text: fullReasoning,  // â­ å‘é€ç´¯ç§¯å†…å®¹
                  thinking_millsec: Date.now() - startTime
                });
              }
            }
          } catch (e) {
            // å¿½ç•¥è§£æé”™è¯¯
          }
          break;

        case 'finish':
          console.log(`[AI SDK Stream] æµå¼å“åº”å®Œæˆ`);
          break;
      }
    }

    // å¤„ç†å‰©ä½™å†…å®¹
    const { normalText: finalNormal, thinkText: finalThink } = thinkParser.flush();
    if (finalNormal) {
      fullContent += finalNormal;
      onChunk?.({ type: ChunkType.TEXT_DELTA, text: fullContent });  // â­ å‘é€ç´¯ç§¯å†…å®¹
    }
    if (finalThink) {
      fullReasoning += finalThink;
      onChunk?.({
        type: ChunkType.THINKING_DELTA,
        text: fullReasoning,  // â­ å‘é€ç´¯ç§¯å†…å®¹
        thinking_millsec: thinkParser.getReasoningTime()
      });
    }

    // æ£€æµ‹æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨ï¼ˆéœ€è¦ç»§ç»­è¿­ä»£ï¼‰
    const hasToolCalls = toolCalls.length > 0 || hasToolUseTags(fullContent);
    
    // å‘é€å®Œæˆäº‹ä»¶ï¼ˆå¦‚æœæœ‰å·¥å…·è°ƒç”¨åˆ™è·³è¿‡ï¼Œç”± provider æ§åˆ¶æœ€ç»ˆå‘é€ï¼‰
    // è¿™æ ·å¯ä»¥é¿å…å¤šè½®å·¥å…·è°ƒç”¨æ—¶é‡å¤åˆ›å»ºå—
    if (!hasToolCalls) {
      if (fullContent) {
        onChunk?.({ type: ChunkType.TEXT_COMPLETE, text: fullContent });
      }
      
      if (fullReasoning) {
        onChunk?.({
          type: ChunkType.THINKING_COMPLETE,
          text: fullReasoning,
          thinking_millsec: thinkParser.getReasoningTime()
        });
      }
    }

    // å‘é€å…¨å±€äº‹ä»¶
    EventEmitter.emit(EVENT_NAMES.STREAM_COMPLETE, {
      provider: 'openai-aisdk',
      model: modelId,
      content: fullContent,
      reasoning: fullReasoning,
      timestamp: Date.now()
    });

    // æ£€æŸ¥å·¥å…·ä½¿ç”¨æ ‡ç­¾ï¼ˆXML æ¨¡å¼ï¼‰
    if (hasToolUseTags(fullContent)) {
      console.log(`[AI SDK Stream] æ£€æµ‹åˆ° XML å·¥å…·ä½¿ç”¨æ ‡ç­¾`);
      EventEmitter.emit(EVENT_NAMES.TOOL_USE_DETECTED, {
        content: fullContent,
        model: modelId
      });
    }

    const endTime = Date.now();
    console.log(`[AI SDK Stream] å®Œæˆï¼Œè€—æ—¶: ${endTime - startTime}ms`);

    // è¿”å›ç»“æœ
    return {
      content: fullContent,
      reasoning: fullReasoning || undefined,
      reasoningTime: fullReasoning ? thinkParser.getReasoningTime() : undefined,
      hasToolCalls,
      nativeToolCalls: toolCalls.length > 0 ? toolCalls : undefined
    };

  } catch (error: any) {
    console.error('[AI SDK Stream] æµå¼å“åº”å¤±è´¥:', error);

    EventEmitter.emit(EVENT_NAMES.STREAM_ERROR, {
      provider: 'openai-aisdk',
      model: modelId,
      error: error.message,
      timestamp: Date.now()
    });

    throw error;
  }
}

/**
 * éæµå¼å“åº”å‡½æ•°
 */
export async function nonStreamCompletion(
  client: AISDKOpenAIProvider,
  modelId: string,
  messages: any[],
  temperature?: number,
  maxTokens?: number,
  additionalParams?: StreamParams
): Promise<StreamResult> {
  console.log(`[AI SDK NonStream] å¼€å§‹éæµå¼å“åº”, æ¨¡å‹: ${modelId}`);

  const startTime = Date.now();
  const signal = additionalParams?.signal;
  const model = additionalParams?.model;
  const mcpTools = additionalParams?.mcpTools || [];
  const mcpMode = additionalParams?.mcpMode || 'function';
  const enableTools = additionalParams?.enableTools !== false;

  // è·å– extraBodyï¼ˆä¼˜å…ˆçº§ï¼šæ¨¡å‹çº§åˆ« > ä¾›åº”å•†çº§åˆ«ï¼‰
  const extraBody = additionalParams?.extraBody || 
                    (model as any)?.extraBody || 
                    (model as any)?.providerExtraBody;

  // è·å– Responses API å¼€å…³é…ç½®ï¼ˆä¼˜å…ˆçº§ï¼šä¾›åº”å•†é…ç½® > æ¨¡å‹é…ç½® > é»˜è®¤å…³é—­ï¼‰
  const providerConfigNonStream = model ? getProviderConfig(model) : null;
  const useResponsesAPI = providerConfigNonStream?.useResponsesAPI || 
                          additionalParams?.useResponsesAPI || 
                          (model as any)?.useResponsesAPI || 
                          false;

  try {
    const processedMessages = messages.map(msg => ({
      role: msg.role as 'system' | 'user' | 'assistant',
      content: msg.content
    }));

    // å‡†å¤‡å·¥å…·é…ç½®
    let tools: any = undefined;
    if (enableTools && mcpTools.length > 0 && mcpMode === 'function') {
      tools = convertMcpToolsToAISDK(mcpTools);
    }

    // ğŸ›¡ï¸ Prompt æ¨¡å¼é˜²å¹»è§‰ï¼šæ·»åŠ  stopSequences
    const isPromptMode = !enableTools && mcpTools.length > 0;
    const stopSequences = isPromptMode ? ['<tool_use_result'] : undefined;

    // å‡†å¤‡ providerOptionsï¼ˆç”¨äºä¼ é€’ extraBodyï¼‰
    let providerOptions: Record<string, any> | undefined;
    if (extraBody && typeof extraBody === 'object' && Object.keys(extraBody).length > 0) {
      providerOptions = {
        openai: extraBody
      };
      console.log(`[AI SDK NonStream] åˆå¹¶è‡ªå®šä¹‰è¯·æ±‚ä½“å‚æ•°: ${Object.keys(extraBody).join(', ')}`);
    }

    // æ ¹æ® useResponsesAPI å¼€å…³é€‰æ‹© API ç±»å‹
    const modelInstance = useResponsesAPI 
      ? client.responses(modelId)  // Responses API
      : client.chat(modelId);       // Chat Completions API

    console.log(`[AI SDK NonStream] ä½¿ç”¨ ${useResponsesAPI ? 'Responses' : 'Chat Completions'} API`);

    const result = await generateText({
      model: modelInstance,
      messages: processedMessages,
      ...(temperature !== undefined && { temperature }),
      ...(maxTokens !== undefined && { maxTokens }),
      abortSignal: signal,
      ...(tools && { tools }),
      ...(providerOptions && { providerOptions }),
      ...(stopSequences && { stopSequences }),
    });

    const endTime = Date.now();
    console.log(`[AI SDK NonStream] å®Œæˆï¼Œè€—æ—¶: ${endTime - startTime}ms`);

    // æå–æ¨ç†å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
    const reasoning = (result as any).reasoning;

    return {
      content: result.text,
      reasoning,
      reasoningTime: reasoning ? endTime - startTime : undefined,
      hasToolCalls: (result.toolCalls?.length ?? 0) > 0,
      nativeToolCalls: result.toolCalls as any[]
    };

  } catch (error: any) {
    console.error('[AI SDK NonStream] éæµå¼å“åº”å¤±è´¥:', error);
    throw error;
  }
}
